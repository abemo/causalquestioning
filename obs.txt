Sensitive > Naive:
    - Always better when episodes => infinity
    - Sensitive better w/ bigger discrepancy between environments (and choices)
    - if a discrepancy between distributions in the model are very slim, then the naive agent
    is the best (at least at first) since it is getting so many bonus datapoints

Sensitive > Deaf:
    For Sensitive Policy to be better than Deaf, the Sensitive Policy must be able
    to identify information and extract information faster than a Deaf agent can just
    identify the optimal choices in its own environment. This extrapolation requires some
    fine-tuning of parameters, but generally is helped by epsilon in 0.05-0.10 range.

Some things to test:
    Policies:
        - adjustment policy,
            if there is a discrepancy of only one node, use some transportability calculus
            to compute probablilities across different environments/datasets
        - A policy where communication received is not in the form of a datapoint but rather
        of the form P(Y|do(X), W)

    Environments change sometime during testing? -- Don't know how to test