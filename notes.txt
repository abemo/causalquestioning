AGENTS
- policies
    - (1) no communication
        -  does not receive information, but can share comm. w/ agents who use comm.
    - (2) naive communication
    - (3) communication of only transferable w/o adjustment
    - (4) communication if all transferable w/ adjustment

- methods:
    - find S-node loc.
        - compare model CPTs using KL divergence
        - returns a dictionary w/ "confidence" of each node having S node attached

    - P(Y|do(X), W) == P(Y|X, W)
        - if can't do this with just model, we can compare datapoints
        - OR just assume this is always true... because it is

    - choose optimally
        - if experimental == observable, use both ?
            - else (won't happen...) use experimental
        - if there is no data, "experiment"
        - if there is no data on the value of W, "experiment"
        - loop through choices, and choose one that maximizes the value of Y (reward/outcome)

    - get data from (single) agent/friend
        - if friend is new, add a knowledge object for that agent
            - self.domains are identical
            - self.model is universal/non-S node model?
            - Do agents with S-nodes know where those S-nodes are themselves?
                - can an agent think it does not have an S-node when it does,
                and think that another agent without one has one where it has one?
        - add most recent experiment/observation datapoint of that agent to knowledge about that agent
            - self.most_recent
        - maybe an I know an agent's entire knowledge every time I comm. with it?

    - get wanted query:
        - P(Y|do(X), W)
            - if experimental == observational, P(Y|X, W)

    - world/environment class
        - uses SCM
        - with inputted X (input vars), returns dictionary with the values returned for each observable variable


Questions for Dr. Forney:
1. What is the best way to determine where an 'S' (sample-selection) node is? My idea:
    - Node with greatest greatest KL-divergence (magnitude) compared to others
    (using conditional probabilities of each node)
    - require confidence as well as magnitude
        - confidence could be a function of the number of samples:
            - more samples + discrepancy = more likely there is an S-node
            - less samples = possibility that noise is skewing

    - in the end, our agent should be able to determine if there is a difference between
    two models, and where that difference lies
        - we want to minimize the frequency of this being miscalculated, because then it would
        incorrectly screw with our policy

2. If there is more than one agent that can communicate and can have different models, how would
we deal with the case that there are two agents who both of sample-selection nodes on different nodes
in their model?
    Then, they would each have to identify that there are two places where SS-bias comes in to play.
        Is it feasible to adjust for this?
        If not, we can stick with just one agent, who has a "universal" model to adjust for biases.
            This agent has at most one node difference between other agents in the system.
                To get all agents to be able to communicate with all others, there must always be at most
                1 node difference between agents.



sID notes:
- U: set of background/endogenous variables
- V: set of endogenous variables assumed to be observable
- Joint probability distribution P(u) over U
- Pa(Y): set of observable parents of Y, including Y
- An(Y): set of observable ancestors of Y, including Y
- De(Y): set of observable descendants of Y, including Y
- P*: Probability from a different environment
- G sub(Y): induced subgraph G containing nodes in Y and all arrows between such nodes
- G sub(line(X) Z): edge subgraph of G where all incoming arrows into X and all outgoing arrows from Z are removed
- D: G with S nodes pointing to divergent nodes in between G and G*
  - D = An(Y) if Y is a descendant of all nodes
  - 

S-node on Z
P*(Y|do(X), W) = summation over Z [ P(y|do(X),z,w)P*(z|x))]